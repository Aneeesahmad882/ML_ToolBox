{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9eee9c-abd6-40d5-b60d-b3cbf39c5bc9",
   "metadata": {},
   "source": [
    "# Answer1\n",
    "The three measures of central tendency are:\n",
    "\n",
    "1-Mean: The mean, or average, is calculated by summing up all the values in a dataset and then dividing by the number of values. It is sensitive to extreme values (outliers) in the data.\n",
    "\n",
    "2-Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. If there is an even number of values, the median is the average of the two middle values. The median is less sensitive to extreme values compared to the mean.\n",
    "\n",
    "3-Mode: The mode is the value that appears most frequently in a dataset. A dataset may have one mode, more than one mode (multimodal), or no mode at all. Unlike the mean and median, the mode is not affected by extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733cf66c-2845-4483-8ff7-ded219d30fe7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4696e2-c5f3-48f5-98a4-bad400932bea",
   "metadata": {},
   "source": [
    "# Answer2\n",
    "The mean, median, and mode are measures of central tendency used to describe the center or typical value of a dataset. Here are the key differences and how they are calculated:\n",
    "\n",
    "1-Mean:\n",
    "\n",
    "Use: The mean is sensitive to extreme values (outliers) and provides a measure of the average value in the dataset. It is commonly used in situations where the distribution of values is roughly symmetrical and not highly skewed.\n",
    "\n",
    "2-Median:\n",
    "Calculation: The middle value when the dataset is ordered. If there is an even number of values, the median is the average of the two middle values.\n",
    "Use: The median is less sensitive to extreme values and is a good measure of central tendency for skewed distributions. It is particularly useful when the dataset has outliers that could disproportionately affect the mean.\n",
    "\n",
    "3-Mode:\n",
    "\n",
    "Calculation: The value(s) that appear most frequently in the dataset.\n",
    "Use: The mode is useful when you want to identify the most common value(s) in a dataset. Unlike the mean and median, the mode can be applied to both numerical and categorical data.\n",
    "\n",
    "How they are used together:\n",
    "\n",
    "In a symmetrical distribution with no outliers, the mean, median, and mode are often very close to each other.\n",
    "In a skewed distribution or one with outliers, the median might be a better indicator of central tendency than the mean.\n",
    "The mode is useful for identifying the most common values, but a dataset may have no mode or multiple modes.\n",
    "Examining all three measures provides a more comprehensive understanding of the central tendency of a dataset, taking into account different aspects such as skewness and the presence of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ca668-6751-456b-83e3-807a64e20434",
   "metadata": {},
   "source": [
    "# Answer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c90ef9b-56ff-4270-86d1-ddbefeb655f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_data = [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cea4c79-75b8-406c-b67b-b6f3d6863316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.01875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#mean\n",
    "np.mean(height_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a19d96fb-dff0-4cad-bba8-914ce98a6f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#median\n",
    "np.median(height_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd954a8-7ea2-4c91-9164-5d610d741d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_628/3367174520.py:3: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  stats.mode(height_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([177.]), count=array([3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mode\n",
    "from scipy import stats\n",
    "stats.mode(height_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31e403-2dc7-4cbd-bd1d-948d0041b146",
   "metadata": {},
   "source": [
    "# Answer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df77c86-6100-48cd-a7fe-2d006f14fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be92dd8-03ee-46da-8946-30bfc23ae8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7885814036548633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find standard Divation:\n",
    "np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ab261-1bc3-499a-b4b8-ae489bde1e4c",
   "metadata": {},
   "source": [
    "# Answer5\n",
    "Measures of dispersion, such as range, variance, and standard deviation, provide insights into the spread or variability of a dataset. Here's how they are used:\n",
    "\n",
    "1-Range:\n",
    "\n",
    "Calculation: Range is the difference between the maximum and minimum values in a dataset.\n",
    "\n",
    "Range=Maximum value−Minimum value\n",
    "Use: Range gives a quick and simple measure of the spread. However, it is sensitive to outliers and may not provide a robust measure of variability.\n",
    "\n",
    "2-Variance:\n",
    "\n",
    "Calculation: Variance is the average of the squared differences from the mean. It provides a measure of how far each data point in the set is from the mean.\n",
    "\n",
    "Use: Variance quantifies the overall variability of the dataset. However, it is in squared units, which can be less intuitive. The standard deviation is often preferred for interpretation.\n",
    "\n",
    "3-Standard Deviation:\n",
    "\n",
    "Calculation: Standard deviation is the square root of the variance.\n",
    "Standard Deviation=Underoot(Variance)\n",
    "\n",
    "Use: Standard deviation provides a measure of the average distance between each data point and the mean. It is in the same units as the original data, making it more interpretable than variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0562ef51-c26c-4a36-8468-34539fefedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class A - Range: 20, Variance: 50.0, Standard Deviation: 7.0710678118654755\n",
      "Class B - Range: 40, Variance: 206.0, Standard Deviation: 14.352700094407323\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Exam scores for two classes\n",
    "class_a_scores = np.array([75, 80, 85, 90, 95])\n",
    "class_b_scores = np.array([60, 75, 80, 95, 100])\n",
    "\n",
    "# Calculate Range\n",
    "range_a = np.max(class_a_scores) - np.min(class_a_scores)\n",
    "range_b = np.max(class_b_scores) - np.min(class_b_scores)\n",
    "\n",
    "# Calculate Variance\n",
    "variance_a = np.var(class_a_scores)\n",
    "variance_b = np.var(class_b_scores)\n",
    "\n",
    "# Calculate Standard Deviation\n",
    "std_dev_a = np.std(class_a_scores)\n",
    "std_dev_b = np.std(class_b_scores)\n",
    "\n",
    "# Print results\n",
    "print(\"Class A - Range: {}, Variance: {}, Standard Deviation: {}\".format(range_a, variance_a, std_dev_a))\n",
    "print(\"Class B - Range: {}, Variance: {}, Standard Deviation: {}\".format(range_b, variance_b, std_dev_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429bba5-698c-4e9b-967a-1dc04f20b702",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d21d729-1fd3-46f2-8b1d-4a4e2fbac214",
   "metadata": {},
   "source": [
    "# Answer6\n",
    "A Venn diagram is a visual representation of the relationships between different sets or groups. It uses overlapping circles or other shapes to illustrate the extent to which the sets have elements in common. Venn diagrams are widely used in various fields, including mathematics, logic, statistics, computer science, and business.\n",
    "\n",
    "Here are the key components of a Venn diagram:\n",
    "\n",
    "1-Circles (or shapes): Each circle represents a set, and the overlap between circles represents the intersection of those sets.\n",
    "\n",
    "2-Intersection: The overlapping region(s) of the circles represent the elements that are common to the sets involved. The size of the overlap indicates the degree of intersection between sets.\n",
    "\n",
    "3-Non-overlapping regions: The non-overlapping portions of the circles represent elements that are unique to each set.\n",
    "\n",
    "4-Universal set: The entire space enclosed by the diagram represents the universal set, which includes all possible elements relevant to the context.\n",
    "\n",
    "Venn diagrams are helpful for visually understanding and comparing the relationships between different sets. They are commonly used to illustrate concepts such as:\n",
    "\n",
    "Union: The combined set of elements from two or more sets.\n",
    "Intersection: The set of elements common to two or more sets.\n",
    "Complement: The set of elements not included in a particular set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cc90f-c2da-4443-9d23-02260050c4a7",
   "metadata": {},
   "source": [
    "# Answer7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d279cdcd-35ad-4f50-b0bf-d55ec233ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ∩ B: {2, 6}\n",
      "A ∪ B: {0, 2, 3, 4, 5, 6, 7, 8, 10}\n"
     ]
    }
   ],
   "source": [
    "# Given sets\n",
    "A = {2, 3, 4, 5, 6, 7}\n",
    "B = {0, 2, 6, 8, 10}\n",
    "\n",
    "# Intersection (A ∩ B)\n",
    "intersection_result = A.intersection(B)\n",
    "\n",
    "# Union (A ∪ B)\n",
    "union_result = A.union(B)\n",
    "\n",
    "# Print the results\n",
    "print(\"A ∩ B:\", intersection_result)\n",
    "print(\"A ∪ B:\", union_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08dc811-9d70-4390-b95e-986e7ebbc3d6",
   "metadata": {},
   "source": [
    "# Answer8\n",
    "Skewness is a statistical measure that describes the asymmetry or lack of symmetry in a distribution of data. In other words, skewness measures the degree and direction of skew (departure from horizontal symmetry) in a dataset.\n",
    "\n",
    "There are three types of skewness:\n",
    "\n",
    "1-Positive Skewness (Right Skew):\n",
    "\n",
    "In a positively skewed distribution, the tail on the right side is longer or fatter than the left side.\n",
    "The majority of the data points cluster on the left side, and the distribution extends more to the right.\n",
    "The mean is typically greater than the median.\n",
    "\n",
    "2-Negative Skewness (Left Skew):\n",
    "\n",
    "In a negatively skewed distribution, the tail on the left side is longer or fatter than the right side.\n",
    "The majority of the data points cluster on the right side, and the distribution extends more to the left.\n",
    "The mean is typically less than the median.\n",
    "\n",
    "3-Zero Skewness:\n",
    "\n",
    "A distribution is considered symmetric (zero skewness) when the two sides are mirror images of each other.\n",
    "The mean and median are equal in a symmetric distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1131aae-8dd1-4f95-85b4-0393eefecee5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c54ab99d-3fef-450d-b7cd-786247548f89",
   "metadata": {},
   "source": [
    "# Answer9\n",
    "In a right-skewed distribution (positively skewed), the tail on the right side is longer or fatter than the left side. This means that there are some unusually high values that pull the mean to the right of the median. In a right-skewed distribution:\n",
    "\n",
    "*The mean is typically greater than the median.\n",
    "This is because the mean is influenced by extreme values, and in a right-skewed distribution, the presence of high values increases the overall average. On the other hand, the median is less affected by extreme values, as it represents the middle value when the data is ordered. Therefore, in a right-skewed distribution, the median is relatively lower compared to the mean.\n",
    "\n",
    "*In summary:\n",
    "\n",
    "Right-skewed distribution: Mean > Median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996d6a5-6796-4837-b887-5e6a0616f5cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2729e634-722b-43db-b824-95493552d7d4",
   "metadata": {},
   "source": [
    "# Answer10\n",
    "Differences:\n",
    "\n",
    "1-Units of Measurement:\n",
    "\n",
    "Covariance is in the units of the product of the units of the two variables.\n",
    "Correlation is a dimensionless quantity, as it is normalized by the product of the standard deviations.\n",
    "\n",
    "2-Scale:\n",
    "\n",
    "Covariance can take any value between -infinite and +infinite making it difficult to interpret the degree of association.\n",
    "Correlation is standardized, always falling between -1 and 1, which makes it easier to interpret.\n",
    "\n",
    "3-Interpretation:\n",
    "\n",
    "Covariance only indicates the direction of the relationship (positive, negative, or none).\n",
    "Correlation provides both the direction and strength of the linear relationship.\n",
    "\n",
    "Use in Statistical Analysis:\n",
    "\n",
    "Covariance: It is used to identify the direction of the relationship between two variables. However, it has limitations due to its scale-dependent nature, making it challenging to compare covariances between different pairs of variables.\n",
    "\n",
    "Correlation: It is widely used in statistical analysis because of its standardized scale, allowing for easier comparison of the strength and direction of relationships. Correlation is particularly useful when working with variables on different scales. It helps in identifying the linear association between variables and is a key tool in regression analysis, where the strength of the relationship is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c3c9b9-6770-4b1b-bd77-c82e77148796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between X and Y: 1.5\n",
      "Correlation coefficient between X and Y: 0.7745966692414834\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "Y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Calculate covariance\n",
    "covariance_matrix = np.cov(X, Y)\n",
    "covariance_xy = covariance_matrix[0, 1]\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(X, Y)[0, 1]\n",
    "\n",
    "# Print the results\n",
    "print(\"Covariance between X and Y:\", covariance_xy)\n",
    "print(\"Correlation coefficient between X and Y:\", correlation_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b686b1-61dc-41d7-86b4-8b1dfdc2baac",
   "metadata": {},
   "source": [
    "# Answer11\n",
    "The sample mean is calculated by summing up all the values in a dataset and then dividing by the number of observations (sample size):\n",
    "\n",
    "sample_mean = sum(data)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12c9e63-bea1-4566-883e-aba82694289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "data = [12, 15, 18, 21, 24, 27, 30]\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = sum(data) / len(data)\n",
    "\n",
    "# Print the result\n",
    "print(\"Sample Mean:\", sample_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f96fc-f9fe-4a56-b914-ec15bca9a8e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "660c4c7f-3d8c-498f-8b26-5b677f540ef9",
   "metadata": {},
   "source": [
    "# Answer12\n",
    "For a normal distribution, which is a symmetric and bell-shaped distribution, the measures of central tendency—mean, median, and mode—are all equal. In other words:\n",
    "\n",
    "Mean (μ): The mean of a normal distribution is located at the center of the distribution. For a perfectly symmetrical normal distribution, the mean is equal to the peak of the distribution.\n",
    "\n",
    "Median: The median is also at the center of the distribution for a normal distribution. Since the distribution is symmetric, the median is the same as the mean.\n",
    "\n",
    "Mode: The mode of a normal distribution is the value at which the distribution reaches its peak. For a normal distribution, the mode is also equal to the mean and median.\n",
    "\n",
    "In summary, for a perfectly normal distribution:\n",
    "\n",
    "Mean=Median=Mode\n",
    "\n",
    "This relationship holds true for any normal distribution, regardless of its mean or standard deviation. It's important to note that in practice, real-world data may not perfectly conform to a normal distribution, but the central tendency measures still exhibit a close relationship in symmetric, bell-shaped distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e54bdf-ac54-4b5b-8074-88338b5e3b73",
   "metadata": {},
   "source": [
    "# Answer13\n",
    "Covariance and correlation are both measures used in statistics to describe the relationship between two random variables, but they have some key differences:\n",
    "\n",
    "1-Definition:\n",
    "\n",
    "Covariance: Covariance measures how two variables change together. It indicates the degree to which changes in one variable correspond to changes in another. The covariance can be positive, negative, or zero.\n",
    "Correlation: Correlation is a standardized measure of the strength and direction of the linear relationship between two variables. It scales the covariance by the product of the standard deviations of the two variables, resulting in a dimensionless quantity that ranges from -1 to 1.\n",
    "\n",
    "2-Scale:\n",
    "\n",
    "Covariance: Covariance is not standardized and can take any value between −∞ and + ∞.\n",
    "This makes it challenging to interpret the degree of association between variables, especially when comparing different pairs of variables.\n",
    "Correlation: Correlation is standardized, always falling between -1 and 1. The correlation coefficient provides a more interpretable measure of the strength and direction of the linear relationship.\n",
    "\n",
    "3-Units:\n",
    "\n",
    "Covariance: The units of covariance are the product of the units of the two variables. This makes interpretation difficult when variables are measured in different units.\n",
    "Correlation: Correlation is dimensionless, making it easier to compare the strength of relationships between variables measured in different units.\n",
    "\n",
    "4-Interpretation:\n",
    "\n",
    "Covariance: Covariance only indicates the direction of the relationship (positive, negative, or none) and whether the variables tend to increase or decrease together.\n",
    "Correlation: Correlation provides both the direction and strength of the linear relationship. The correlation coefficient, \n",
    "r, ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no linear correlation.\n",
    "\n",
    "5-Range:\n",
    "\n",
    "Covariance: The range of covariance is unrestricted and depends on the scales of the variables. Larger values of covariance do not necessarily imply a stronger relationship.\n",
    "Correlation: The range of correlation is standardized and fixed between -1 and 1, providing a clear indication of the strength and direction of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed75cf6-ef4d-4b95-b00b-85fe634e1bd6",
   "metadata": {},
   "source": [
    "# Answer14\n",
    "Outliers can significantly impact measures of central tendency (mean, median, mode) and measures of dispersion (range, variance, standard deviation). Their influence depends on the nature and magnitude of the outlier. Here's how outliers affect these measures:\n",
    "\n",
    "1-Mean:\n",
    "\n",
    "Effect: Outliers can heavily influence the mean because the mean is sensitive to extreme values. A single very large or very small value can pull the mean towards it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8887573f-04e0-4d37-bfc4-f55258b3e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean1: 2.5\n",
      "Mean2: 22.0\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "#without outliers\n",
    "data1 = [1,2,3,4]\n",
    "mean1 = np.mean(data1)\n",
    "print(\"Mean1:\",mean1)\n",
    "#data with outliers\n",
    "data2 = [1,2,3,4,100]\n",
    "mean2 = np.mean(data2)\n",
    "print(\"Mean2:\",mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e7fd3-fed3-4a46-a893-79e073d0431e",
   "metadata": {},
   "source": [
    "2-Median:\n",
    "\n",
    "Effect: Outliers have little to no impact on the median because the median is not influenced by extreme values. It represents the middle value when the data is ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "742823d8-e0b8-471b-98ca-b93ee6537c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median1: 2.5\n",
      "Median2: 3.0\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "#without outliers\n",
    "data1 = [1,2,3,4]\n",
    "median1 = np.median(data1)\n",
    "print(\"Median1:\",mean1)\n",
    "#data with outliers\n",
    "data2 = [1,2,3,4,100]\n",
    "median2 = np.median(data2)\n",
    "print(\"Median2:\",median2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1e802-0a5c-4fea-b4bc-5a941bb2a43d",
   "metadata": {},
   "source": [
    "3-Mode:\n",
    "\n",
    "Effect: Outliers typically do not affect the mode. The mode is the most frequently occurring value in a dataset, and it is not sensitive to extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe74e04a-bbff-489e-af2d-e4b444eea91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode1: ModeResult(mode=array([1]), count=array([1]))\n",
      "Mode2: ModeResult(mode=array([1]), count=array([1]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/3348139285.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode1 = stats.mode(data)\n",
      "/tmp/ipykernel_84/3348139285.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode2 = stats.mode(data2)\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "#without outliers\n",
    "from scipy import stats\n",
    "data1 = [1,2,3,4]\n",
    "mode1 = stats.mode(data)\n",
    "print(\"Mode1:\",mode1)\n",
    "#data with outliers\n",
    "data2 = [1,2,3,4,100]\n",
    "mode2 = stats.mode(data2)\n",
    "print(\"Mode2:\",mode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cf2d5-a4f5-4a3d-85a6-1ce377a6e5a5",
   "metadata": {},
   "source": [
    "4-Range:\n",
    "\n",
    "Effect: Outliers can significantly impact the range, as it is the difference between the maximum and minimum values.\n",
    "A single extreme value can greatly increase the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eed75b5-4e3d-42da-8998-d4047c35877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range1: 3\n",
      "Range2: 99\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "#without outliers\n",
    "data1 = [1,2,3,4]\n",
    "range1 = np.ptp(data1)\n",
    "print(\"Range1:\",range1)\n",
    "#data with outliers\n",
    "data2 = [1,2,3,4,100]\n",
    "range2 = np.ptp(data2)\n",
    "print(\"Range2:\",range2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca435f-6e8a-43cc-89d2-b1214997f9a5",
   "metadata": {},
   "source": [
    "5-Variance and Standard Deviation:\n",
    "\n",
    "Effect: Outliers can increase the variance and standard deviation. These measures quantify the spread of data, \n",
    "and extreme values contribute to higher variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95b42c68-b823-4bae-854d-70fc06123a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: 2.5 std1: 1.118033988749895\n",
      "var2: 22.0 std2: 39.01281840626232\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "#without outliers\n",
    "data1 = [1,2,3,4]\n",
    "var1 = np.var(data1)\n",
    "std1= np.std(data1)\n",
    "print(\"var1:\",mean1,\"std1:\",std1)\n",
    "#data with outliers\n",
    "data2 = [1,2,3,4,100]\n",
    "var2 = np.var(data2)\n",
    "std2= np.std(data2)\n",
    "print(\"var2:\",mean2,\"std2:\",std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af668254-d5fa-43b4-be4d-21dcd23b1097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
